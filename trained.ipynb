{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, ViTFeatureExtractor, ViTConfig, TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image and Labels Loading and Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data from CSV\n",
    "csv_file = \"clean_MovieGenre.csv\"  # Path to your CSV file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Specify the binarized columns\n",
    "binarized_columns = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', \n",
    "                     'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music', 'Musical', \n",
    "                     'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, processor):\n",
    "        self.images = images\n",
    "        self.labels = labels.astype(np.float32) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Process image using the provided processor\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        processed_image = inputs.pixel_values.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "        return {\"pixel_values\": processed_image, \"labels\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"downloaded_images\" #sample_images for developing, downloaded_images for final\n",
    "images = []\n",
    "labels = []\n",
    "batch_size = 128  \n",
    "\n",
    "# Load images and labels in batches\n",
    "num_batches = len(df) // batch_size + 1\n",
    "\n",
    "for batch_num in tqdm(range(num_batches)):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = min((batch_num + 1) * batch_size, len(df))\n",
    "    \n",
    "    batch_df = df.iloc[start_idx:end_idx]\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for index, row in batch_df.iterrows():\n",
    "        filename = str(row.iloc[0]) + \".jpg\"  # filenames match the imdbIDs\n",
    "        label = [int(row[column]) for column in binarized_columns]  # Extract binarized labels for each genre\n",
    "\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        try:\n",
    "            image = Image.open(image_path)  # Open image using PIL\n",
    "            image = image.convert(\"RGB\")  # Convert image to RGB mode if necessary\n",
    "            image_array = np.array(image)  # Convert PIL Image to numpy array\n",
    "            batch_images.append(image_array)\n",
    "            batch_labels.append(label)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    # Concatenate the batches of images and labels\n",
    "    if batch_images:\n",
    "        images.append(np.array(batch_images))\n",
    "        labels.append(np.array(batch_labels))\n",
    "\n",
    "# Concatenate all batches into single numpy arrays\n",
    "if images:\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the loaded data\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Display sample images\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(9):\n",
    "\tax = plt.subplot(3, 3, i + 1)\n",
    "\tplt.imshow(images[i])\n",
    "\tplt.axis('off')\n",
    "\tplt.title([column for column, label in zip(binarized_columns, labels[i]) if label == 1], fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the split datasets\n",
    "print(\"Training images shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "\n",
    "print(\"Validation images shape:\", X_val.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)\n",
    "\n",
    "print(\"Testing images shape:\", X_test.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Distribution\n",
    "train_label_distribution = np.sum(y_train, axis=0)\n",
    "val_label_distribution = np.sum(y_val, axis=0)\n",
    "test_label_distribution = np.sum(y_test, axis=0)\n",
    "\n",
    "combined_data = {\n",
    "    \"Label\": binarized_columns,\n",
    "    \"Train Distribution\": train_label_distribution,\n",
    "    \"Validation Distribution\": val_label_distribution,\n",
    "    \"Test Distribution\": test_label_distribution\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(combined_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pixel values are in the range of 0 to 255 and are float32\n",
    "X_train = np.clip(X_train, 0, 255)\n",
    "X_val = np.clip(X_val, 0, 255)\n",
    "X_test = np.clip(X_test, 0, 255)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "X_train = np.transpose(X_train, (0, 3, 1, 2))\n",
    "X_val = np.transpose(X_val, (0, 3, 1, 2))\n",
    "X_test = np.transpose(X_test, (0, 3, 1, 2))\n",
    "\n",
    "# Ensure labels are int64\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_val = y_val.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_dataset(X, y, shard_size=10000):\n",
    "    for i in range(0, len(X), shard_size):\n",
    "        yield {'pixel_values': X[i:i + shard_size], 'labels': y[i:i + shard_size]}\n",
    "\n",
    "train_shards = list(shard_dataset(X_train, y_train))\n",
    "\n",
    "train_datasets = [Dataset.from_dict(shard) for shard in train_shards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_shards = list(shard_dataset(X_val, y_val))\n",
    "test_shards = list(shard_dataset(X_test, y_test))\n",
    "\n",
    "# Process shards as needed\n",
    "val_datasets = [Dataset.from_dict(shard) for shard in val_shards]\n",
    "test_datasets = [Dataset.from_dict(shard) for shard in test_shards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = concatenate_datasets(train_datasets)\n",
    "val_dataset = concatenate_datasets(val_datasets)\n",
    "test_dataset = concatenate_datasets(test_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the default ViT model configuration\n",
    "vit_config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# Update the image size in the configuration\n",
    "vit_config = ViTConfig(\n",
    "    image_size=(268, 182),\n",
    "    problem_type=\"multi_label_classification\",\n",
    "\tnum_labels=len(binarized_columns),\n",
    "    is_classifier=True,\n",
    "    classifier_activation=\"sigmoid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Specification\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', config=vit_config, ignore_mismatched_sizes=True)\n",
    "\n",
    "#utilize cuda if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Utilize MPS backend if available (specific to Apple Silicon)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,   \n",
    "    num_train_epochs=3,             \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,               \n",
    "    save_steps=200,                 \n",
    "    evaluation_strategy=\"epoch\",    \n",
    "    fp16=True,                      \n",
    "    gradient_accumulation_steps=2,  \n",
    "    dataloader_num_workers=2,       \n",
    "    learning_rate=2e-5,            \n",
    "    weight_decay=0.01,             \n",
    "    save_total_limit=2,            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    logits = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "    \n",
    "    # Apply sigmoid to get probabilities\n",
    "    probabilities = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "    \n",
    "    # Define a threshold to get binary predictions\n",
    "    threshold = 0.5\n",
    "    predictions = (probabilities > threshold).astype(int)\n",
    "    \n",
    "    f1 = f1_score(labels, predictions, average='micro')\n",
    "    # accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'f1_score': f1,\n",
    "        # 'accuracy': accuracy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Trainer\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\").float()  # Ensure labels are float\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure processor has the correct image size\n",
    "processor.size = (268, 182)  # Set the processor size to match the model\n",
    "\n",
    "# Perform inference\n",
    "model.eval()\n",
    "predicted_probabilities = []\n",
    "\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    # Process batch inputs\n",
    "    batch_images = X_test[i:i+batch_size]\n",
    "    \n",
    "    # Convert numpy arrays to lists of PIL images and process\n",
    "    batch_inputs = processor(images=[Image.fromarray(img.transpose(1, 2, 0)) for img in batch_images], return_tensors=\"pt\") \n",
    "    batch_inputs = {k: v.to(device) for k, v in batch_inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(**batch_inputs)\n",
    "    \n",
    "    # Get the predicted logits\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Convert logits to probabilities using sigmoid\n",
    "    probabilities = torch.sigmoid(logits)\n",
    "    \n",
    "    # Append predicted probabilities for this batch\n",
    "    predicted_probabilities.append(probabilities.cpu().numpy())\n",
    "\n",
    "# Concatenate predicted probabilities for all batches\n",
    "predicted_probabilities = np.concatenate(predicted_probabilities, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "y_test_np = np.array(y_test)\n",
    "predicted_probabilities_np = np.array(predicted_probabilities)\n",
    "\n",
    "# Ensure that the arrays have the appropriate shape\n",
    "y_test_np = np.vstack([np.array(y) for y in y_test_np])\n",
    "\n",
    "# Define the threshold for binary classification\n",
    "threshold = 0.5\n",
    "\n",
    "# Threshold predicted probabilities to obtain binary predictions\n",
    "predicted_labels_np = (predicted_probabilities_np > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store F1 scores and accuracies for each label\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "predicted_binary_labels = (predicted_probabilities > threshold).astype(int)\n",
    "\n",
    "# Iterate over each label\n",
    "for i, label in enumerate(binarized_columns):\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test_np[:, i], predicted_labels_np[:, i], average='binary')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test[:, i], predicted_binary_labels[:, i])\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "data = {\n",
    "    \"Label\": binarized_columns,\n",
    "    \"F1 Score\": f1_scores,\n",
    "    \"Accuracy\": accuracies\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Compute average F1 score\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 score:\", avg_f1_score)\n",
    "\n",
    "# Compute average accuracy\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(\"Average accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(X_test, y_test, predicted_probabilities, binarized_columns, threshold=0.5):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < len(X_test):\n",
    "            poster = X_test[idx].transpose(1, 2, 0)  # Transpose back to (height, width, channels)\n",
    "            true_labels = [binarized_columns[i] for i, label in enumerate(y_test[idx]) if label == 1]\n",
    "            predicted_genre_probabilities = predicted_probabilities[idx]\n",
    "\n",
    "            # Sort predicted probabilities and select labels based on the number of true labels\n",
    "            num_true_labels = len(true_labels)\n",
    "            top_predicted_idx = np.argsort(predicted_genre_probabilities)[::-1][:num_true_labels]\n",
    "            predicted_genre_labels = [binarized_columns[i] for i in top_predicted_idx]\n",
    "            top_predicted_probabilities = predicted_genre_probabilities[top_predicted_idx]\n",
    "\n",
    "            ax.imshow(poster)\n",
    "            ax.set_title(f\"True Genres: {true_labels}\\nPredicted Genres: {predicted_genre_labels}\\nProbabilities: {top_predicted_probabilities}\", fontsize=10)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')  # Hide empty subplots\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display(X_test, y_test, predicted_probabilities, binarized_columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
