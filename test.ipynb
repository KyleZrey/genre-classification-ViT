{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, Trainer, TrainingArguments, ViTFeatureExtractor, ViTForImageClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "accelerate.__version__\n",
    "transformers.__version__, accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data from CSV\n",
    "csv_file = \"clean_MovieGenre.csv\"  # Path to your CSV file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Specify the binarized columns\n",
    "binarized_columns = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', \n",
    "                     'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music', 'Musical', \n",
    "                     'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western']\n",
    "image_folder = \"sample_images\"  # sample_images for developing, downloaded_images for final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "batch_size = 128  \n",
    "\n",
    "# Load images and labels in batches\n",
    "num_batches = len(df) // batch_size + 1\n",
    "\n",
    "for batch_num in tqdm(range(num_batches)):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = min((batch_num + 1) * batch_size, len(df))\n",
    "    \n",
    "    batch_df = df.iloc[start_idx:end_idx]\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for index, row in batch_df.iterrows():\n",
    "        filename = str(row.iloc[0]) + \".jpg\"  # filenames match the imdbIDs\n",
    "        label = [int(row[column]) for column in binarized_columns]  # Extract binarized labels for each genre\n",
    "\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        try:\n",
    "            image = Image.open(image_path)  # Open image using PIL\n",
    "            image = image.convert(\"RGB\")  # Convert image to RGB mode if necessary\n",
    "            image_array = np.array(image)  # Convert PIL Image to numpy array\n",
    "            batch_images.append(image_array)\n",
    "            batch_labels.append(label)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    # Concatenate the batches of images and labels\n",
    "    if batch_images:\n",
    "        images.append(np.array(batch_images))\n",
    "        labels.append(np.array(batch_labels))\n",
    "\n",
    "# Concatenate all batches into single numpy arrays\n",
    "if images:\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "# Print the shapes of the loaded data\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('off')\n",
    "    plt.title([column for column, label in zip(binarized_columns, labels[i]) if label == 1], fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)  # change test_size if want quicker runtime\n",
    "\n",
    "# Print the shapes of the split datasets\n",
    "print(\"Training images shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing images shape:\", X_test.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)\n",
    "\n",
    "train_label_distribution = np.sum(y_train, axis=0)\n",
    "test_label_distribution = np.sum(y_test, axis=0)\n",
    "\n",
    "combined_data = {\n",
    "    \"Label\": binarized_columns,\n",
    "    \"Train Distribution\": train_label_distribution,\n",
    "    \"Test Distribution\": test_label_distribution\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(combined_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset from Numpy arrays\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"image\": list(X_train),\n",
    "    \"label\": list(y_train)\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"image\": list(X_test),\n",
    "    \"label\": list(y_test)\n",
    "})\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(dataset_dict)\n",
    "first_example = dataset_dict[\"train\"][0]\n",
    "print(first_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "from torchvision.transforms import Resize, Compose\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "size = processor.size[\"height\"]\n",
    "\n",
    "_train_transforms = Compose([\n",
    "    Resize((size, size)),\n",
    "])\n",
    "\n",
    "_val_transforms = Compose([\n",
    "    Resize((size, size)),\n",
    "])\n",
    "\n",
    "def train_transforms(example):\n",
    "    images = [ToPILImage()(np.array(image)) for image in example['image']] \n",
    "    transformed_images = [_train_transforms(image) for image in images]  \n",
    "    example['image'] = transformed_images\n",
    "    return example\n",
    "\n",
    "def val_transforms(example):\n",
    "    images = [ToPILImage()(np.array(image)) for image in example['image']]  \n",
    "    transformed_images = [_val_transforms(image) for image in images]  \n",
    "    example['image'] = transformed_images\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(train_transforms)\n",
    "test_dataset = test_dataset.map(val_transforms)\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, collate_fn=collate_fn, batch_size=16)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, collate_fn=collate_fn, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Specification\n",
    "# processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k',\n",
    "    num_labels=len(binarized_columns),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"precision\",\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    preds = (logits > 0.5).astype(int)\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    return {\"f1\": f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "predicted_probabilities = []\n",
    "\n",
    "# Test DataLoader\n",
    "test_loader = torch.utils.data.DataLoader(dataset_dict[\"test\"], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'label'}\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.sigmoid(outputs.logits)\n",
    "        predicted_probabilities.append(probabilities.cpu().numpy())\n",
    "\n",
    "# Concatenate predicted probabilities for all batches\n",
    "predicted_probabilities = np.concatenate(predicted_probabilities, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "y_test_np = np.vstack([np.array(item) for item in dataset_dict[\"test\"]['label']])\n",
    "predicted_probabilities_np = np.array(predicted_probabilities)\n",
    "\n",
    "# Define the threshold for binary classification\n",
    "threshold = 0.5\n",
    "\n",
    "# Threshold predicted probabilities to obtain binary predictions\n",
    "predicted_labels_np = (predicted_probabilities_np > threshold).astype(int)\n",
    "\n",
    "# Initialize lists to store F1 scores and accuracies for each label\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "# Iterate over each label\n",
    "for i, label in enumerate(binarized_columns):\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test_np[:, i], predicted_labels_np[:, i], average='binary')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_np[:, i], predicted_labels_np[:, i])\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "data = {\n",
    "    \"Label\": binarized_columns,\n",
    "    \"F1 Score\": f1_scores,\n",
    "    \"Accuracy\": accuracies\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(data)\n",
    "print(df_metrics)\n",
    "\n",
    "# Compute average F1 score\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 score:\", avg_f1_score)\n",
    "\n",
    "# Compute average accuracy\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(\"Average accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(X_test, y_test, predicted_probabilities, binarized_columns, threshold=0.5):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < len(X_test):\n",
    "            poster = X_test[idx]\n",
    "            true_labels = [binarized_columns[i] for i, label in enumerate(y_test[idx]) if label == 1]\n",
    "            predicted_genre_probabilities = predicted_probabilities[idx]\n",
    "\n",
    "            # Sort predicted probabilities and select labels based on the number of true labels\n",
    "            num_true_labels = len(true_labels)\n",
    "            top_predicted_idx = np.argsort(predicted_genre_probabilities)[::-1][:num_true_labels]\n",
    "            predicted_genre_labels = [binarized_columns[i] for i in top_predicted_idx]\n",
    "            top_predicted_probabilities = predicted_genre_probabilities[top_predicted_idx]\n",
    "\n",
    "            ax.imshow(poster)\n",
    "            ax.set_title(f\"True Genres: {true_labels}\\nPredicted Genres: {predicted_genre_labels}\\nProbabilities: {top_predicted_probabilities}\", fontsize=10)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')  # Hide empty subplots\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Note: Ensure X_test, y_test, predicted_probabilities are available in the scope when calling display function.\n",
    "display(X_test, y_test, predicted_probabilities, binarized_columns)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
